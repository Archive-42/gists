const wait = time => new Promise((resolve) => setTimeout(resolve, time));

wait(3000).then(() => console.log('Hello!')); // 'Hello!'

import speculation from 'speculation';

const wait = (
  time,
  cancel = Promise.reject() // By default, don't cancel
) => speculation((resolve, reject, onCancel) => {
  const timer = setTimeout(resolve, time);

  // Use onCancel to clean up any lingering resources
  // and then call reject(). You can pass a custom reason.
  onCancel(() => {
    clearTimeout(timer);
    reject(new Error('Cancelled'));
  });
}, cancel); // remember to pass in cancel!

wait(200, wait(500)).then(
  () => console.log('Hello!'),
  (e) => console.log(e)
); // 'Hello!'

wait(200, wait(50)).then(
  () => console.log('Hello!'),
  (e) => console.log(e)
); // [Error: Cancelled]
// @flow
const crypto = require('crypto');

module.exports = WebpackStableChunkHash;

function WebpackStableChunkHash() {}

WebpackStableChunkHash.prototype.apply = function(compiler) {
  //
  // For a while, webpack has had issues with [chunkhash] being unstable and not reflecting the actual
  // md5 of the module.
  //
  // While stable, deterministic builds are one issue, the biggest issue with [chunkhash] is that it runs too
  // early, before optimization. This means that a change to your optimizer output will *not* be reflected in the
  // chunkhash, which may break CDNs or other long-term caching strategies.
  //
  // This plugin runs as the absolute last plugin in 'after-optimize-chunk-assets' to ensure that it is getting
  // the source that will be written to disk. It then hashes that. All options that work with normal `[chunkhash]`
  // apply here.
  //
  compiler.plugin('compilation', function(compilation) {
    const outputOptions = compilation.outputOptions;
    const hashFunction = outputOptions.hashFunction;
    const hashDigest = outputOptions.hashDigest;
    const hashDigestLength = outputOptions.hashDigestLength;

    // Storage for chunk filenames. This is important as `chunk.files` is usually a 1-element array,
    // but not always.
    const chunkRecords = {};
    compilation.plugin('chunk-asset', function(chunk, fileName) {
      chunkRecords[chunk.id] = fileName;
    });

    compilation.plugin('after-optimize-chunk-assets', function(chunks) {
      // process.nextTick() is a horrible hack to ensure this runs after source map.
      process.nextTick(function() {
        const fullHash = crypto.createHash(hashFunction);
        let usedChunkHash = false;

        // File sources are in compilations.assets[file].
        for(let i = 0; i < chunks.length; i++) {
          const chunk = chunks[i];
          const usesChunkHash = !chunk.hasRuntime() ||
            (compilation.mainTemplate.useChunkHash && compilation.mainTemplate.useChunkHash(chunk));

          // If we're not using `[chunkhash]`, no need for this processing.
          if (!usesChunkHash) continue;
          usedChunkHash = true;

          const oldHash = chunk.hash;
          const file = chunkRecords[chunk.id];
          // This is a Source object, like RawSource, SourceMapSource, or ConcatSource
          const source = compilation.assets[file];

          // Intentionally *not* using source.updateHash(hash) here, as it's only the hash of the output
          // that counts. We don't want to change chunkhash just because a source file changed in a way
          // that was not reflected in the actual output.
          chunk.hash = crypto.createHash(hashFunction).update(source.source()).digest(hashDigest);
          chunk.renderedHash = chunk.hash.substr(0, hashDigestLength);

          // Prevents an error when createChunkAssets() is run again.
          delete compilation.assets[file];

          // Let's update the chunk cache so we don't have to do any other work.
          delete compilation.cache[oldHash]; // Delete old entry
          const cacheName = "c" + chunk.id;
          compilation.cache[cacheName] = {
            hash: chunk.hash,
            source: source
          };
        }

        // Easy out - we don't need to modify anything.
        if (!usedChunkHash) return;

        // Update the entire compilation's hash to reflect what has changed.
        compilation.fullHash = fullHash.digest(hashDigest);
        compilation.hash = compilation.fullHash.substr(0, hashDigestLength);

        // Okay, we've updated some hashes, so we have to call `createChunkAssets` again.
        compilation.createChunkAssets();
      });
    });
  });
};

import React, { useEffect } from 'react';
import hoistStatics from '../../HOCs/hoist-statics';
import { connect } from 'react-redux';
import {
  getShouldSignOut,
  setShouldSignOut,
  getDidAuthFail,
  signInStatusChanged,
  setMagicUser,
} from './ethereum-authentication-reducer';
import { getUser } from '../user-profile/user-profile-reducer';
import useMagicLink from './use-magic-link';
import PropTypes from 'prop-types';

const apiKey = 'pk_live_NOT_A_REAL_KEY_GET_YOUR_OWN';

const mapStateToProps = state => ({
  shouldSignOut: getShouldSignOut(state),
  ethDidAuthFail: getDidAuthFail(state),
  user: getUser(state),
});

const mapDispatchToProps = {
  setShouldSignOut,
  signInStatusChanged,
  setMagicUser,
};

const connectComponent = connect(mapStateToProps, mapDispatchToProps);

const withMagicLink = Component => {
  const WithMagicLink = props => {
    const {
      shouldSignOut,
      setShouldSignOut,
      signInStatusChanged,
      setMagicUser,
    } = props;

    const { signIn, signOut, user } = useMagicLink(apiKey, signInStatusChanged);

    useEffect(() => {
      if (shouldSignOut) {
        setShouldSignOut(false);
        signOut();
      }
    }, [shouldSignOut]);

    useEffect(() => {
      setMagicUser(user);
    }, [user]);

    return (
      <Component
        {...props}
        magicLinkSignIn={signIn}
        magicLinkSignOut={signOut}
        isSignedInToMagic={user.isSignedIn}
        magicUser={user}
      />
    );
  };

  WithMagicLink.propTypes = {
    shouldSignOut: PropTypes.bool,
    setShouldSignOut: PropTypes.func,
    signInStatusChanged: PropTypes.func,
    setMagicUser: PropTypes.func,
  };

  return connectComponent(WithMagicLink);
};

export default hoistStatics(withMagicLink);

// START: closure.
(async () => {
  // Test URL.
  const url = '/?rest_route=/wp/v2/posts&per_page=100';

  // Example options.
  const options = {
    credentials: 'include',
    headers: {
      'content-type': 'application/json',
    },
    method: 'GET',
  }

  // Ajax.
  try {
    const result = await fetch(url, options);
    const payload = await result.json();

    // Log response.
    console.log(payload);
  } catch (e) {
    // No-op.
  }

  // END: closure.
})();

import { Transform } from 'stream'
import { StringDecoder } from 'string_decoder'
import { Composer, Parser } from 'yaml'

/**
 * A Transform stream that accepts either strings or Buffers as input, and
 * emits YAML Documents.
 *
 * Calling the stream's `end()` method may be required to emit the last
 * document.
 *
 * ```js
 * import { createReadStream } from 'fs'
 * const source = createReadStream('input.yaml')
 * const docStream = new DocStream()
 * docStream.on('data', doc => console.log(doc.toJS()))
 * source.pipe(docStream)
 * ```
 */
export class DocStream extends Transform {
  constructor(options = {}) {
    super({
      ...options,
      decodeStrings: false,
      emitClose: true,
      objectMode: true
    })
    this.composer = new Composer(doc => this.push(doc))
    this.decoder = new StringDecoder(options.defaultEncoding || 'utf8')
    this.parser = new Parser(this.composer.next)
  }

  _flush(done) {
    this.parser.parse('', false)
    this.composer.end()
    done()
  }

  _transform(chunk, _, done) {
    try {
      const src = Buffer.isBuffer(chunk) ? this.decoder.write(chunk) : chunk
      this.parser.parse(src, true)
      done()
    } catch (error) {
      done(error) // should never happen
    }
  }
}

YUI.add('z-aliased-attr', function (Y) {

/**
Aliased Attribute Extension

This extension provides the "aliased" property to Attribute config.
This is largely a convenience for referring to attributes internally
by more descriptive names than their URL parameter-safe name.

    var PieModel = Y.Base.create('pieModel', Y.Model, [Y.Z.AliasedAttr], {}, {
        ATTRS: {
            c: {
                aliased: 'crust',
                value: 'flaky'
            },
            slices: {
                value: 8
            }
        }
    });

    var applePie = new PieModel({ flavor: 'apple' });

    applePie.get('c');              // => 'flaky'
    applePie.getAliased('crust');   // => 'flaky'

    applePie.getAliased('slices');  // => 8         (note fall-through)
    applePie.getAliased('s');       // => undefined

    applePie.getAliased('flavor');  // => 'apple'   (supports ad-hoc attributes)

    var appleJSON = applePie.toJSON();
    //  appleJSON = {
    //      flavor: 'apple',
    //      c: 'flaky',
    //      slices: 8
    //  }

@author Daniel Stockman
@since 2012/09
**/

var hasOwn = Object.prototype.hasOwnProperty,
    hashArray = Y.Array.hash,
    objectKeys = Y.Object.keys,
    YBase = Y.Base;

// add "aliased" to attribute config whitelist
YBase._ATTR_CFG = YBase._ATTR_CFG.concat("aliased");
YBase._ATTR_CFG_HASH = hashArray(YBase._ATTR_CFG);

/**
@class AliasedAttr
@namespace Z
@extensionfor Base
**/
function AliasedAttr() {}

AliasedAttr.prototype = {
    /**
    Call _initAliasedAttrs during initializer. This must
    be run after the host class initializer, therefore it
    cannot be called from this extension's constructor.

    @method initializer
    @protected
    **/
    initializer: function () {
        this._initAliasedAttrs();
    },

    /**
    Cache attribute names and bind a memoized _getAliased
    method into _getAliasedName.

    @method _initAliasedAttrs
    @private
    **/
    _initAliasedAttrs: function () {
        Y.log('_initAliasedAttrs', 'debug', 'AliasedAttr');
        this._attrNames = this._getAttrNames();
        this._getAliasedName = Y.cached(Y.bind(this._getAliased, this));
    },

    /**
    Caches the list of attribute names that we may need
    to operate on. Protected class attributes are removed
    from this list, as they will never be aliased.

    @method _getAttrNames
    @private
    **/
    _getAttrNames: function () {
        Y.log('_getAttrNames', 'debug', 'AliasedAttr');
        var attrNames = objectKeys(this._state.data);

        return this._filterAttrNames(attrNames);
    },

    /**
    Duplicate Model's toJSON() filtering when caching the
    list of attribute names. The initialized and destroyed
    attribute names are always removed, and the Model-specific
    values only if the host is a Model.

    @method _filterModelAttrs
    @param {Array} attrNames
    @return {Array} with the undesired attribute names removed.
    @private
    **/
    _filterAttrNames: function (attrNames) {
        Y.log('_filterAttrNames', 'debug', 'AliasedAttr');
        var hashed = hashArray(attrNames);

        // remove default attributes that are never aliased
        delete hashed.destroyed;
        delete hashed.initialized;

        // remove model metadata if necessary
        if (this._isYUIModel) {
            delete hashed.clientId;

            if (this.idAttribute !== 'id') {
                delete hashed.id;
            }
        }

        return objectKeys(hashed);
    },

    /**
    Utility method to retrieve the attribute name associated
    with a given alias. This method is bound to the instance
    during initialization, wrapped in a Y.Cached() function.

    Each time an attribute name is successfully matched, that
    name is removed from the private _attrNames array to prevent
    redundant searching (the value is cached, anyway).

    @method _getAliased
    @param {String} alias
    @return {String} the aliased attribute name, if any
    @private
    **/
    _getAliased: function (alias) {
        Y.log('_getAliased ' + alias, 'debug', 'AliasedAttr');
        var stateData = this._state.data,
            attrNames = this._attrNames,
            attrName,
            datum,
            idx = 0,
            len = attrNames.length;

        for (; idx < len; idx += 1) {
            attrName = attrNames[idx];
            // ensure that the state object actually owns the property
            if (hasOwn.call(stateData, attrName)) {
                // get the data directly, bypassing State#getAll(name, true)
                datum = stateData[attrName];
                // check for the 'aliased' property, regardless of laziness
                if (datum && (datum.lazy && datum.lazy.aliased === alias || datum.aliased === alias)) {
                    // remove attrName from filtering array, so it is no longer tested
                    attrNames.splice(idx, 1);
                    return attrName;
                }
            }
        }
    },

    /**
    Retrieve an aliased attribute value by it's alias
    instead of the actual name.

    If the alias does not exist, attempt to retrieve the
    attribute value with the alias provided.

    @method getAliased
    @param {String} alias
    @return {Mixed}
    **/
    getAliased: function (alias) {
        Y.log('getAliased ' + alias, 'debug', 'AliasedAttr');

        var attrName = this._getAliasedName(alias);
        if (attrName) {
            return this.get(attrName);
        }

        return this.get(alias);
    }
};

Y.namespace('Z').AliasedAttr = AliasedAttr;

}, '3.7.3', {
    requires: [
        'base-build'
    ]
});

YUI.add("z-aliased-attr-test", function (Y) {

var suite = new Y.Test.Suite("z-aliased-attr"),

    testATTRS = {
        a: {
            aliased: 'alpha',
            value: 'A'
        },
        b: {
            value: 'B'
        },
        c: {
            aliased: 'gamma',
            lazyAdd: false,
            value: 'C'
        }
    },

    TestClass = Y.Base.create('testClass', Y.Base,  [Y.Z.AliasedAttr], {}, { ATTRS: testATTRS }),
    TestModel = Y.Base.create('testModel', Y.Model, [Y.Z.AliasedAttr], {}, { ATTRS: testATTRS });

suite.add(new Y.Test.Case({

    name: "Aliased Attribute Lifecycle",

    "_initAliasedAttrs should setup _attrNames property as an array": function () {
        var instance = new TestClass();

        Y.ObjectAssert.ownsKey('_attrNames', instance, "Didn't cache _attrNames property");
        Y.Assert.isArray(instance._attrNames, "_attrNames wasn't an array");
    },

    "_initAliasedAttrs (Base) should filter protected attributes out of _attrNames array": function () {
        var instance = new TestClass(),
            names = instance._attrNames;

        Y.ArrayAssert.containsItems(['a', 'b', 'c'], names, "Incorrect filtering: " + names);
    },

    "_initAliasedAttrs (Model) should filter protected attributes out of _attrNames array": function () {
        var instance = new TestModel(),
            names = instance._attrNames;

        Y.ArrayAssert.containsItems(['id', 'a', 'b', 'c'], names, "Incorrect filtering: " + names);
    },

    "_initAliasedAttrs (Model) should filter custom idAttribute out of _attrNames array": function () {
        // override Y.Model's default, 'id'
        TestModel.prototype.idAttribute = 'a';

        var instance = new TestModel(),
            names = instance._attrNames;

        Y.ArrayAssert.containsItems(['a', 'b', 'c'], names, "custom idAttribute not removed: " + names);

        // reset TestModel to Y.Model's default
        delete TestModel.prototype.idAttribute;
    },

    "_initAliasedAttrs should cache _getAliasedName function": function () {
        var instance = new TestClass();

        Y.ObjectAssert.ownsKey('_getAliasedName', instance, "Didn't cache _getAliasedName function");
        Y.Assert.isFunction(instance._getAliasedName, "_getAliasedName function not created");
    },

    "getAlias() should be provided on instance": function () {
        var instance = new TestClass();

        Y.Assert.isFunction(instance.getAliased, "getAliased() missing on instance");
    }

}));

suite.add(new Y.Test.Case({

    name: "Aliased Attribute Getters",

    "getAliased() should return value when valid alias passed in": function () {
        var instance = new TestClass();

        Y.Assert.areSame('A', instance.getAliased('alpha'), "getAliased('alpha') did not return 'A'");
    },

    "getAliased() should return undefined when invalid alias passed in": function () {
        var instance = new TestClass();

        Y.Assert.isUndefined(instance.getAliased('beta'), "getAliased('beta') should not return 'B'");
    },

    "getAliased() should return value when valid non-alias passed in": function () {
        var instance = new TestClass();

        Y.Assert.areSame('B', instance.getAliased('b'), "getAliased('b') did not return 'B'");
    },

    "getAliased() should return ad-hoc value when valid non-alias passed in": function () {
        var instance = new TestModel({
            delta: 'D'
        });

        Y.Assert.areSame('D', instance.getAliased('delta'), "getAliased('delta') did not return 'D'");
    },

    "getAliased() should return correct values over several calls": function () {
        var instance = new TestClass();

        Y.Assert.areSame('A', instance.getAliased('alpha'), "getAliased('alpha') did not return 'A'");
        Y.ArrayAssert.containsItems(['b', 'c'], instance._attrNames, "_attrNames 'a' not removed after success");

        // during development, the search was corrupted by multiple failed searches
        Y.Assert.isUndefined(instance.getAliased('beta'), "getAliased('beta') should not return 'B'");
        Y.Assert.isUndefined(instance.getAliased('beta'), "getAliased('beta') should not loop twice");
        Y.ArrayAssert.containsItems(['b', 'c'], instance._attrNames, "_attrNames changed after failures");

        Y.Assert.areSame('C', instance.getAliased('gamma'), "getAliased('gamma') did not return 'C'");
        Y.ArrayAssert.containsItems(['b'], instance._attrNames, "_attrNames 'c' not removed after success");
    },

    "stub": function () {
        // var instance = new TestClass();
    }

}));

Y.namespace("Z")["z-aliased-attr-test-suite"] = suite;

}, "@VERSION@", { requires: ["test-console", "z-aliased-attr", "model"] });

// This is our subapp's root connected component.
// It can render more components, connected or not, below, just like normally.
// Usually we'd render it in <Provider> and be done with it.

class App extends Component { ... }
export default connect(mapStateToProps)(App)
// However we don't have to call ReactDOM.render(<Provider><App /></Provider>)
// if we're interested in hiding the fact that it's a Redux app.
//
// Maybe we want to be able to run multiple instances of it in the same "bigger" app
// and keep it as a complete black box, with Redux being an implementation detail.
// To hide Redux behind a React API, we can wrap it in a special component that
// initializes the store in the constructor. This way every instance will be independent.
//
// Note that this is *not* recommended for parts of the same app that share data.
// But it can be useful when the bigger app has zero access to smaller apps' internals,
// and we'd like to keep the fact that they are implemented with Redux an implementation detail.
// Each component instance will have its own store, so they won't "know" about each other.

import React, { Component } from 'react'
import { Provider } from 'react-redux'
import reducer from './reducers'
import App from './App'

class Root extends Component {
  constructor(props) {
    super(props)
    this.store = createStore(reducer)
  }
  
  render() {
    return (
      <Provider store={this.store}>
        <App />
      </Provider>
    )
  }
}
"use strict";

(function (factory) {
	if (typeof Benchmark !== "undefined") {
		factory(Benchmark);
	} else {
		factory(require("benchmark"));
	}
})(function (Benchmark) {
	var suite = new Benchmark.Suite;

	Benchmark.prototype.setup = function () {
		var concatContainer = [];
		var pushContainer = [];
		var dataToFeed = [];
		
		var initialArrayLength = 1e3;
		
		for (var j = 0; j < initialArrayLength; j++){
		    concatContainer.push('stuff' + j);
		    pushContainer.push('stuff' + j);
		    dataToFeed.push('stuff' + j);
		}
	};


	suite.add("concatContainer = concatContainer.concat(dataToFeed);", function () {
		concatContainer = concatContainer.concat(dataToFeed);
	});

	suite.add("pushContainer.push(...dataToFeed);", function () {
		pushContainer.push(...dataToFeed);
	});

	suite.on("cycle", function (evt) {
		console.log(" - " + evt.target);
	});

	suite.on("complete", function (evt) {
		console.log(new Array(30).join("-"));

		var results = evt.currentTarget.sort(function (a, b) {
			return b.hz - a.hz;
		});

		results.forEach(function (item) {
			console.log((idx + 1) + ". " + item);
		});
	});

	console.log("array augmenting: push read vs concat");
	console.log(new Array(30).join("-"));
	suite.run();
});

//Cache polyfil to support cacheAPI in browsers
importScripts('/cache-polyfill.js');

//Cache name
var staticCache = "my-static-files"; 

//Files to cache
var filesToCache = [
  "/",
  "images/logo.jpg",
  "css/main.css",
  "js/app.js"
];

//Adding a eventlistener to install event
self.addEventListener("install", function (event) {
  //Installation steps
  event.waitUntil(
    caches.open(staticCache)
    .then(function (cache) {
      //[] of files to cache & if any of the file not present compelete `addAll` will fail
      return cache.addAll(urlsToCache)
      .then(function () {
        console.log("Successfully cached.");
      })
      .cache(function (error) {
        console.log("Failed to cache ", error);
      })
    })
  );
});
//Activate event will be triggered once after registering, also used to clean up caches

self.addEventListener("activate", function (event) {
  var cacheWhitelist = ['my-static-files'];
  
	event.waitUntil(
		caches.keys()
		.then(function (allCaches) {
			//Check all caches and delete old caches here
			allCaches.map(function (cacheName) {
				if (cacheWhitelist.indexOf(cacheName) === -1) {
					return caches.delete(cacheName);
				}
			});
		})
	);
});
//After install, fetch event is triggered for every page request
self.addEventListener("fetch", function (event) {
	console.log("Request -->", event.request.url);

	//To tell browser to evaluate the result of event
	event.respondWith(
		caches.match(event.request) //To match current request with cached request it
		.then(function(response) {
			//If response found return it, else fetch again.
			return response || fetch(event.request);
		})
		.catch(function(error) {
			console.error("Error: ", error);
		})
  );
});
const cacheName = 'v1';

const cacheAssets = [
  'index.html',
  'about.html',
  '/css/style.css',
  '/js/main.js'
];

// Call Install Event
self.addEventListener('install', e => {
  console.log('Service Worker: Installed');

  e.waitUntil(
    caches
      .open(cacheName)
      .then(cache => {
        console.log('Service Worker: Caching Files');
        cache.addAll(cacheAssets);
      })
      .then(() => self.skipWaiting())
  );
});

// Call Activate Event
self.addEventListener('activate', e => {
  console.log('Service Worker: Activated');
  // Remove unwanted caches
  e.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames.map(cache => {
          if (cache !== cacheName) {
            console.log('Service Worker: Clearing Old Cache');
            return caches.delete(cache);
          }
        })
      );
    })
  );
});

// Call Fetch Event
self.addEventListener('fetch', e => {
  console.log('Service Worker: Fetching');
  e.respondWith(fetch(e.request).catch(() => caches.match(e.request)));
});

const cacheName = 'v2';

// Call Install Event
self.addEventListener('install', e => {
  console.log('Service Worker: Installed');
});

// Call Activate Event
self.addEventListener('activate', e => {
  console.log('Service Worker: Activated');
  // Remove unwanted caches
  e.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames.map(cache => {
          if (cache !== cacheName) {
            console.log('Service Worker: Clearing Old Cache');
            return caches.delete(cache);
          }
        })
      );
    })
  );
});

// Call Fetch Event
self.addEventListener('fetch', e => {
  console.log('Service Worker: Fetching');
  e.respondWith(
    fetch(e.request)
      .then(res => {
        // Make copy/clone of response
        const resClone = res.clone();
        // Open cahce
        caches.open(cacheName).then(cache => {
          // Add response to cache
          cache.put(e.request, resClone);
        });
        return res;
      })
      .catch(err => caches.match(e.request).then(res => res))
  );
});

/* @flow */

export default class Element {
  get previousToken(): ?Element {
      if (this._parentElement) {
          return this._parentElement.previousToken;
      }

      return null;
  }

  _parentElement: Element;

  loc() {
      let prevToken = this.previousToken;
      while (prevToken) {
          let lines = ['asdf', 'asdf'];
          if (lines.length > 1) {
              while (prevToken) {
                  prevToken = prevToken.previousToken; // saying it's potentially null
              }
              break;
          }
          prevToken = prevToken.previousToken; // error here
      }
  }
}
YUI({
    modules: {
        'promise-each': {
            fullpath: './promise-each.js',
            requires: ['promise']
        }
    }
}).use('promise-each', function (Y) {
    Y.Promise.each(['foo', 'bar', Y.when('teapot'), 'baz'], function (val, idx) {
        if (idx === 1) {
            throw new Error('threw at index 1');
        }
        Y.log('"' + val + '" at index %d' + idx);
    })
        .then(function (result) {
            Y.log(result);
        })
        .catch(function (ex) {
            Y.error(ex);
        });
});

// node --expose_gc test-http-parser-big.js
// Run this program with valgrind or efence to expose a problem.

var assert = require('assert');
var HTTPParser = process.binding('http_parser').HTTPParser;
var CRLF = "\r\n";

var headersComplete = 0;
var messagesComplete = 0;

var parser = new HTTPParser('REQUEST');

parser.headers = [];
parser.url = '';

parser.onHeaders = function(headers, url) {
  parser.headers = parser.headers.concat(headers);
  parser.url += url;
};

parser.onHeadersComplete = function(info) {
  headersComplete++;
  console.log("url", info.url);
};

parser.onBody = function(b, start, len) {
};

parser.onMessageComplete = function() {
  messagesComplete++;
};


function flushPool() {
  new Buffer(Buffer.poolSize - 1);
  gc();
}


// We use a function to eliminate references to the Buffer b
// We want b to be GCed. The parser will hold a bad reference to it.
function start() {
  var b = Buffer('POST /1');
  flushPool();

  console.log("parse the first part of the message");
  parser.execute(b, 0, b.length);
}

function end() {
  var b = Buffer('/22 HTTP/1.1' + CRLF +
    'Content-Type: text/plain' + CRLF +
    'Content-Length: 4' + CRLF +
    CRLF +
    'pong');

  console.log("parse the second part of the message");
  parser.execute(b, 0, b.length);
  parser.finish();
}


var count = 0;
var P = start();
flushPool();
end(P);


process.on('exit', function() {
  assert.equal(1, headersComplete);
  assert.equal(1, messagesComplete);
  console.log("done!");
});

var assert = require('assert');
var HTTPParser = process.binding('http_parser').HTTPParser;
var CRLF = "\r\n";

var headersComplete = 0;
var messagesComplete = 0;

function newParser(type) {
  var parser = new HTTPParser(type);

  parser.headers = [];
  parser.url = '';

  parser.onHeaders = function(headers, url) {
    //parser.headers = parser.headers.concat(headers);
    //parser.url += url;
  };

  parser.onHeadersComplete = function(info) {
    headersComplete++;
    console.log("url", info.url);
  };

  parser.onBody = function(b, start, len) {
  };

  parser.onMessageComplete = function() {
    messagesComplete++;
  };

  return parser;
}

function doGC() {
  for (var i = 0; i < 100; i++) {
    gc();
  }
}

function start() {
  var p = newParser('REQUEST');

  var b1 = Buffer('POST /1');

  console.log("parse the first part of the message");
  p.execute(b1, 0, b1.length);

  var b2 = Buffer(10 * 1024 * 1024);  
  var b3 = Buffer('/22/333/4444/55555');
  p.execute(b3, 0, b3.length);

  delete b1;
  delete b2;
  delete b3;

  return p;
}

function end(p) {
  var b = Buffer('/666666/7777777/88888888/ HTTP/1.1' + CRLF +
    'Content-Type: text/plain' + CRLF +
    'Content-Length: 4' + CRLF +
    'A: asdfasdfadfasdfasdfasdfasdf' + CRLF +
    'b: asdfasdfadfasdfasdfasdfasdf' + CRLF +
    'h0: a' + CRLF +
    'y0: asdfasdfadfasdfasdfasdfasdf' + CRLF +
    'z0: asdfasdfadfasdfasdfasdfasdf' + CRLF +
    CRLF +
    'pong');

  console.log("parse the second part of the message");
  p.execute(b, 0, b.length);
  p.finish();
}


var count = 0;
var P = start();
var interval = setInterval(function() {
  if (++count == 100) {
    end(P);
    clearInterval(interval);
  } else {
    Buffer(10 * 1024 * 1024);  
    doGC();
  }
}, 1);


process.on('exit', function() {
  assert.equal(1, headersComplete);
  assert.equal(1, messagesComplete);
  console.log("done!");
});

#!/usr/bin/env node

var path = require('path');
var YUI = require('yui').YUI;

var Y = YUI({
    useSync: true,
    modules: {
        'promise-each': {
            fullpath: path.join(__dirname, 'promise-each.js'),
            requires: ['promise']
        }
    }
}).use('promise-each');

Y.Promise.each(['foo', 'bar', Y.when('teapot'), 'baz'], function (val, idx) {
    if (idx === 1) {
        throw new Error('BOOM at index 1');
    }
    console.log('"%s" at index %d', val, idx);
})
    .then(function (result) {
        console.log('result', result);
    })
    .catch(function (ex) {
        console.error(ex);
    });

document.body.innerHTML = 'Paste or drop items onto this page. View results in console.';


function getPayload(item) {
  const kind = item.kind;
  switch (kind) {
    case 'string': return new Promise(res => item.getAsString(res));
    case 'file': return Promise.resolve(item.getAsFile());
    default: throw new Error('unknown item kind! ' + kind);  
  }    
}

function logObj(type, obj){ 
  console.log(`%c ${type} event`, 'font-weight: bold', new Date().toLocaleTimeString());
  
  const getPayloadAndType = item => {
    const type = item.type;
    return getPayload(item).then(payload => ({type, payload}));
  };

  Array.from(obj.items)
    .sort((a,b) => a.type.localeCompare(b.type))
    .forEach(item => Promise.resolve().then(_ => getPayloadAndType(item)).then(console.log));  
}

document.onpaste =  e => { logObj(e.type, e.clipboardData)};
document.ondrop = e => { e.preventDefault(); logObj(e.type, e.dataTransfer)};
document.ondragover = e => { e.preventDefault(); };


var timer = null;
var domhrtTimeAtStartOfPerformance;
var msgIndex;
var PREQUEUE = 0;   // with a conformant sendMIDIMessage w/ timestamps, could be set to a larger number like 200.

function tick() {
    var msg, delay;

    var domhrtRelativeTime = Math.round(window.performance.webkitNow() -
            domhrtTimeAtStartOfPerformance);

    if (msgIndex=sequenceLength) 
        return;  // we've hit the end of the sequence.  This shouldn't be hit, except for an empty initial sequence.

    msg = sequence[msgIndex];
    delay = msg.timestamp - domhrtRelativeTime;
    
    while (delay <= PREQUEUE ) { // send all messages that are due now.
        output.sendMIDIMessage(msg);

        logMessage("timestamp: " + msg.timestamp + ", domhrtTime: " + domhrtRelativeTime + 
            ", scheduling deviation: " + (domhrtRelativeTime - msg.timestamp));

        msgIndex++;
        if (msgIndex == sequenceLength)
            return; // we've hit the end of the sequence.
        msg = sequence[msgIndex];
        delay = msg.timestamp - domhrtRelativeTime;
    }

    window.setTimeout(tick, delay);  // this will schedule the next tick.
}



function sendMIDISequence() {
    domhrtTimeAtStartOfPerformance = window.performance.webkitNow();
    msgIndex = 0;
    tick();
}
var TimeSeriesRingBuffer = function(size) {
    this._lastTS = 0;
    this._size = size;
    this.reset();
};

TimeSeriesRingBuffer.prototype.reset = function(){
    this._buffer = new Array(this._size);
    for (var i = 0; i < this._size; i++) {
        this._buffer[i] = 0;
    }
};

TimeSeriesRingBuffer.prototype._refresh = function() {
    var currTS = parseInt(new Date().getTime() / 1000, 10);
    var delta = currTS - this._lastTS;

    if (delta > 300) {
        this.reset();
    } else if (delta > 0) {
        for (var i = 1; i < delta + 1; i++) {
            this._buffer[(this._lastTS + i) % this._size] = 0;
        }
    }
    this._lastTS = currTS;
}

TimeSeriesRingBuffer.prototype.push = function() {
    this._refresh();
    this._buffer[this._lastTS % this._size]++;
};

TimeSeriesRingBuffer.prototype.sum = function() {
    this._refresh();
    var count = 0;
    for (var i = 0; i < this._size; i++) {
        count += this._buffer[i];
    }
    return count;
};

TimeSeriesRingBuffer.prototype.avg = function() {
    return this.sum() / this._size;
};
  center: new OpenLayers.LonLat(-7837508, 4537508),
    map: {
      allOverlays:false,
       maxExtent: new OpenLayers.Bounds(-20037508.3427892, -20037508.3427892, 20037508.3427892, 20037508.3427892),
       numZoomLevels: 8,
       maxResolution: 156543.0339,
       controls: [new OpenLayers.Control.LayerSwitcher(), new OpenLayers.Control.TouchNavigation({
       dragPanOptions: {
        enableKinetic: true
       }
      }), new OpenLayers.Control.Zoom()]
    },
                        layers: [
                            new OpenLayers.Layer.OSM("OpenStreetMap", null, {
                                transitionEffect: "resize",
                                attribution: "&copy; <a href='http://www.openstreetmap.org/copyright'>OpenStreetMap</a> contributors"
                            }),
                            new OpenLayers.Layer.XYZ("WP Base Layer - XYZ",
                                    "http://media.washingtonpost.com/wp-srv/special/cartography/tilesets/cultural/reference/basic/${z}_${x}_${y}.gif",
                                    {
                                        isBaseLayer: true,
                                        projection: new OpenLayers.Projection("EPSG:900913"),
                                        maxExtent: new OpenLayers.Bounds(-20037508.34, -20037508.34, 20037508.34, 20037508.34),
                                        maxResolution: 156543.0339
                                    }),
                            new OpenLayers.Layer.WMS( "OpenLayers Basic WMS",
                                    "http://vmap0.tiles.osgeo.org/wms/vmap0",
                                    {layers: 'basic'},
                                    {isBaseLayer:true}),
                            new OpenLayers.Layer.TMS("TMS-Temps, ESPG4:326",
                                    "http://geo.jbjonesjr.com/geoserver/gwc/service/tms/",
                                    {
                                        layername: "jbjonesjr-ws1%3Ageolocated_conditions@EPSG%3A4326@jpeg",
                                        projection: new OpenLayers.Projection("EPSG:4326"),
                                        maxExtent:new OpenLayers.Bounds(-180,-90,180,90),
                                        maxResolution: 360/512/16,
                                        isBaseLayer: false,
                                        type: "png"
                                    }
                            ),
                            new OpenLayers.Layer.TMS("TMS-Temps, ESPG4:900913",
                                    "http://geo.jbjonesjr.com/geoserver/gwc/service/tms/",
                                    {
                                        layername: "jbjonesjr-ws1%3Ageolocated_conditions@EPSG%3A900913@jpeg",
                                        isBaseLayer: false,
                                        type: "png"
                                    }
                            ),
                            new OpenLayers.Layer.WMS(
                                    "Current temperature",
                                    "http://geo.jbjonesjr.com/geoserver/jbjonesjr-ws1/wms",
                                    {
                                        LAYERS: 'jbjonesjr-ws1:geolocated_conditions',
                                        STYLES: 's_temperature',
                                        transparent: true,
                                        format: 'image/png'
                                    },
                                    {
                                        singleTile: false,
                                        //ratio: 1,
                                        //maxResolution: 360 / 512 / 16,
                                       // projection: new OpenLayers.Projection("EPSG:4326"),
                                       // maxExtent: new OpenLayers.Bounds(-180, -90, 180, 90),
                                        isBaseLayer: false//,
                                        //yx: {'EPSG:4326': true}
                                    }
                            )
                        ]
                    }
[ { count: 2523, text: 'ross' },
  { count: 1922, text: 'joey' },
  { count: 1876, text: 'god' },
  { count: 1411, text: 'rachel' },
  { count: 1348, text: 'guy' },
  { count: 1345, text: 'monica' },
  { count: 991, text: 'chandler' },
  { count: 640, text: 'phoebe' },
  { count: 430, text: 'pheeb' },
  { count: 385, text: 'rach' },
  { count: 257, text: 'ben' },
  { count: 239, text: 'emma' },
  { count: 236, text: 'emily' },
  { count: 177, text: 'joe' },
  { count: 172, text: 'janice' },
  { count: 151, text: 'carol' },
  { count: 140, text: 'london' },
  { count: 112, text: 'richard' },
  { count: 110, text: 'mike' },
  { count: 108, text: 'marcel' },
  { count: 98, text: 'mark' },
  { count: 90, text: 'susan' },
  { count: 88, text: 'julie' },
  { count: 87, text: 'bob' },
  { count: 86, text: 'buddy' },
  { count: 76, text: 'frank' },
  { count: 74, text: 'kathy' },
  { count: 72, text: 'charlie' },
  { count: 71, text: 'joey tribbiani' },
  { count: 71, text: 'bing' },
  { count: 69, text: 'ralph lauren' },
  { count: 69, text: 'turkey' },
  { count: 68, text: 'paul' },
  { count: 64, text: 'joshua' },
  { count: 63, text: 'new york' },
  { count: 62, text: 'barry' },
  { count: 60, text: 'joey\'' },
  { count: 60, text: 'gunther' },
  { count: 58, text: 'mona' },
  { count: 58, text: 'god!' },
  { count: 58, text: 'tv' },
  { count: 55, text: 'rachel green' },
  { count: 55, text: 'jack' },
  { count: 55, text: 'monica\'' },
  { count: 54, text: 'santa' },
  { count: 50, text: 'tulsa' },
  { count: 50, text: 'bobby' },
  { count: 50, text: 'porsche' },
  { count: 49, text: 'jill' },
  { count: 48, text: 'ursula' },
  { count: 46, text: 'elizabeth' },
  { count: 46, text: 'chandler\'' },
  { count: 44, text: 'alice' },
  { count: 44, text: 'david' },
  { count: 43, text: 'bill' },
  { count: 43, text: 'day of our lives' },
  { count: 42, text: 'tag' },
  { count: 42, text: 'ross\'' },
  { count: 41, text: 'paris' },
  { count: 40, text: 'pete' },
  { count: 40, text: 'brain' },
  { count: 38, text: 'china' },
  { count: 38, text: 'paolo' },
  { count: 38, text: 'mindy' },
  { count: 38, text: 'valentine\'' },
  { count: 38, text: 'kay' },
  { count: 36, text: 'vega' },
  { count: 36, text: 'danny' },
  { count: 35, text: 'minsk' },
  { count: 34, text: 'estelle' },
  { count: 34, text: 'mary angela' },
  { count: 34, text: 'split' },
  { count: 34, text: 'alan' },
  { count: 32, text: 'guy i' },
  { count: 31, text: 'rachel\'' },
  { count: 30, text: 'amanda' },
  { count: 29, text: 'vermont' },
  { count: 29, text: 'phoebe\'' },
  { count: 29, text: 'chandler bing' },
  { count: 28, text: 'howard' },
  { count: 28, text: 'gary' },
  { count: 28, text: 'ross geller' },
  { count: 28, text: 'joanna' },
  { count: 28, text: 'amy' },
  { count: 28, text: 'hanukkah' },
  { count: 27, text: 'geller' },
  { count: 26, text: 'hugsy' },
  { count: 26, text: 'yemen' },
  { count: 26, text: 'ethan' },
  { count: 26, text: 'monica geller' },
  { count: 26, text: 'janine' },
  { count: 26, text: 'kate' },
  { count: 24, text: 'molly' },
  { count: 24, text: 'larry' },
  { count: 24, text: 'ross!' },
  { count: 24, text: 'michelle' },
  { count: 24, text: 'summer' },
  { count: 24, text: 'school' },
  { count: 24, text: 'steve' },
  { count: 24, text: 'judy' } ]

// transform-split-sibling-variables
// Opposite of http://babeljs.io/docs/plugins/transform-merge-sibling-variables/

export default function ({ types: t }) {
  return {
    visitor: {
      VariableDeclaration(path) {
        if (!path.inList) {
          return;
        }

        const { kind, declarations } = path.node;
        if (declarations.length === 1) {
          return;
        }
        
        path.replaceWithMultiple(
          declarations.map(({ id, init }) => {
            return t.variableDeclaration(kind, [
              t.variableDeclarator(id, init)
            ])
          })
        );                                                                                                                                                                                                                                               
      }
    }
  };
}
'use strict';

var _redux = require('redux');

var _react = require('react');

var _react2 = _interopRequireDefault(_react);

var _reactDom = require('react-dom');

var _reactDom2 = _interopRequireDefault(_reactDom);

var _reduxDevtools = require('redux-devtools');

var _reduxDevtoolsLogMonitor = require('redux-devtools-log-monitor');

var _reduxDevtoolsLogMonitor2 = _interopRequireDefault(_reduxDevtoolsLogMonitor);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

var DevTools = (0, _reduxDevtools.createDevTools)(_react2.default.createElement(_reduxDevtoolsLogMonitor2.default, { theme: 'tomorrow' }));

var Counter = function Counter(_ref) {
  var value = _ref.value;
  var onAdd = _ref.onAdd;
  return _react2.default.createElement(
    'div',
    null,
    _react2.default.createElement(
      'h1',
      null,
      value
    ),
    _react2.default.createElement(
      'button',
      { onClick: onAdd },
      '+'
    )
  );
};

var counter = function counter() {
  var state = arguments.length <= 0 || arguments[0] === undefined ? 0 : arguments[0];
  var action = arguments[1];

  if (action.type === 'inc') {
    return state + 1;
  }
  return state;
};

var store = (0, _redux.createStore)(counter, DevTools.instrument());
var render = function render() {
  _reactDom2.default.render(_react2.default.createElement(
    'div',
    { style: { height: '100%' } },
    _react2.default.createElement(Counter, {
      value: store.getState(),
      onAdd: function onAdd() {
        return store.dispatch({ type: 'inc' });
      }
    }),
    _react2.default.createElement(DevTools, { store: store })
  ), document.getElementById('root'));
};

render();
store.subscribe(render);
const cmds = { linux: 'xdg-open', win32: 'start', darwin: 'open' };
const open = cmds[process.platform];

const tryOpen = (dirname, editors = ['sublime', 'code', open]) => {
  try {
    cp.execSync([editors[0], dirname].join(' '));
    console.log('Opening in ' + editors[0]);
  } catch (err) {
    if (editors.length === 0) {
      throw new Error('Cannot find an editor to open');
    }
    return tryEditors(dirname, editors.slice(1));
  }
};

/**
 * Example usage
 */

const argv = require('minimist')(process.argv.slice(2));

// open the first resolved editor or file manager
if (argv.open === true) {
  tryOpen(path.dirname(__dirname));
  process.exit();
}

// open the specified application
if (typeof argv.open === 'string') {
  tryOpen(path.dirname(__dirname), [argv.open]);
  process.exit();
}
var fs = require('fs')
  , path = require('path')
  , request = require('request')
  , qs = require('querystring')
  , exec = require('child_process').exec
  , crypto = require('crypto')

var twitter_config = JSON.parse( fs.readFileSync( path.resolve(__dirname, 'twitter-config.json'), 'utf-8' ) )

function uuid(){

  var s = [], itoh = '0123456789ABCDEF';

  // Make array of random hex digits. The UUID only has 32 digits in it, but we
  // allocate an extra items to make room for the '-'s we'll be inserting.
  for (var i = 0; i <36; i++) s[i] = Math.floor(Math.random()*0x10);

  // Conform to RFC-4122, section 4.4
  s[14] = 4;  // Set 4 high bits of time_high field to version
  s[19] = (s[19] & 0x3) | 0x8;  // Specify 2 high bits of clock sequence

  // Convert to hex chars
  for (var i = 0; i <36; i++) s[i] = itoh[s[i]];

  // Insert '-'s
  s[8] = s[13] = s[18] = s[23] = '-';

  return s.join('');

  
}

function sha1 (key, body) {
  return crypto.createHmac('sha1', key).update(body).digest('base64')
}

function rfc3986 (str) {
  return encodeURIComponent(str)
    .replace(/!/g,'%21')
    .replace(/\*/g,'%2A')
    .replace(/\(/g,'%28')
    .replace(/\)/g,'%29')
    .replace(/'/g,'%27')
    ;
}

function hmacsign (httpMethod, base_uri, params, consumer_secret, token_secret, body) {
  // adapted from https://dev.twitter.com/docs/auth/oauth
  var base = 
    (httpMethod || 'GET') + "&" +
    encodeURIComponent(  base_uri ) + "&" +
    Object.keys(params).sort().map(function (i) {
      // big WTF here with the escape + encoding but it's what twitter wants
      return escape(rfc3986(i)) + "%3D" + escape(rfc3986(params[i]))
    }).join("%26")
  var key = encodeURIComponent(consumer_secret) + '&'
  if (token_secret) key += encodeURIComponent(token_secret)
  return sha1(key, base)
}

function createAuthHeaders(_oauth, uri, method){

  var form = {}
  var oa = {}
  for (var i in form) oa[i] = form[i]
  for (var i in _oauth) oa['oauth_'+i] = _oauth[i]
  if (!oa.oauth_version) oa.oauth_version = '1.0'
  if (!oa.oauth_timestamp) oa.oauth_timestamp = Math.floor( (new Date()).getTime() / 1000 ).toString()
  if (!oa.oauth_nonce) oa.oauth_nonce = uuid().replace(/-/g, '')
  
  oa.oauth_signature_method = 'HMAC-SHA1'
  
  var consumer_secret = oa.oauth_consumer_secret
  delete oa.oauth_consumer_secret
  var token_secret = oa.oauth_token_secret
  delete oa.oauth_token_secret
  
  var baseurl = uri.protocol + '//' + uri.host + uri.pathname
  var signature = hmacsign(method, baseurl, oa, consumer_secret, token_secret)
  
  // oa.oauth_signature = signature
  // Not used?
  for (var i in form) {
    console.log('i in form '+ i)
    if ( i.slice(0, 'oauth_') in _oauth) {
      // skip 
      console.log('skipping')
    } else {
      delete oa['oauth_'+i]
    }
  }

  // NOTE: I added a space after the commma in the join() to explicitly match the way Twitter is doing it
  var authorization = 
    'Authorization: OAuth '+Object.keys(oa).sort().map(function (i) {return i+'="'+rfc3986(oa[i])+'"'}).join(', ')

  authorization += ', oauth_signature="'+rfc3986(signature)+'"'
  
  return authorization

  
}

let rows = {}

export default function(props = [], state = []) {
  return function(target) {
    const proto = Object.create(target.prototype)

    proto.shouldComponentUpdate = function(newProps, newState) {
      let id = (this._update_id = this._update_id || Math.random())

      for (var i = 0; i < props.length; i++) {
        const name = props[i]
        const oldVal = this.props[name]
        const newVal = newProps[name]
        if (newVal !== oldVal) {
          if (localStorage.traceUpdates == '*') {
            const rowName = `${target.name} prop '${name}'`
            rows[rowName] = rows[rowName] || { renders: 0, instances: {} }
            rows[rowName].renders++
            rows[rowName].instances[id] = rows[rowName].instances[id] || 0
            rows[rowName].instances[id]++
          }
          return true
        }
      }

      for (var i = 0; i < state.length; i++) {
        const name = state[i]
        const oldVal = this.state[name]
        const newVal = newState[name]
        if (newVal !== oldVal) {
          if (localStorage.traceUpdates == '*') {
            const rowName = `${target.name} state '${name}'`
            rows[rowName] = rows[rowName] || { renders: 0, instances: {} }
            rows[rowName].renders++
            rows[rowName].instances[id] = rows[rowName].instances[id] || 0
            rows[rowName].instances[id]++
          }
          return true
        }
      }

      return false
    }

    target.prototype = proto
  }
}

function enable() {
  console.log('enabled update tracing')
  localStorage.traceUpdates = '*'
}

function disable() {
  console.log('disabled update tracing')
  localStorage.traceUpdates = ''
}

function print() {
  if (Object.keys(rows).length == 0) {
    console.log('nothing to print')
    return
  }

  for (var k in rows) {
    rows[k].instances = Object.keys(rows[k].instances).length
    rows[k]['renders per instance'] = rows[k].renders / rows[k].instances
  }

  console.table(rows, ['renders', 'instances', 'renders per instance'])
  rows = {}
}

window.updates = {
  enable,
  disable,
  print
}

@update(['foo', 'bar'])
@update(['foo', 'bar'], ['state'])
import { useState, useEffect, useRef } from 'react';
import Web3 from 'web3';
import Fortmatic from 'fortmatic';

const usePromise = () => {
  const ref = [];
  const container = useRef(ref);

  ref[0] = new Promise((resolve, reject) => {
    ref[1] = resolve;
    ref[2] = reject;
  });

  return container.current;
};

const useFortmatic = apiKey => {
  const [accounts, setAccounts] = useState([]);
  const [web3Ready, setWeb3Ready] = usePromise();
  const [web3IsInitialized, setWeb3IsInitialized] = useState(false);

  const signIn = async () => {
    const { web3 } = await web3Ready;
    // Get the current user account addresses.
    // Auth if needed.
    // signIn returns a promise that should wait for signIn
    // to complete before it resolves.
    return web3.eth
      .getAccounts()
      .then(newAccounts => {
        if (newAccounts[0] !== accounts[0]) setAccounts(newAccounts);
        return newAccounts;
      })
      .catch(() => {
        const newAccounts = [];
        setAccounts(newAccounts);
        return newAccounts;
      });
  };

  const signOut = async () => {
    const { fm } = await web3Ready;
    // signOut returns a promise that will wait
    // until signout is complete to resolve.
    await fm.user.logout();
    setAccounts([]);
  };

  const isSignedIn = accounts => accounts.length > 0;

  // Fire only once after components mounts.
  useEffect(() => {
    const initializeWeb3 = async () => {
      const fm = new Fortmatic(apiKey);
      const web3 = new Web3(fm.getProvider());
      // This needs to run before we update state
      // if we want to enable users to stay signed
      // in between page reloads.
      (await fm.user.isLoggedIn()) && signIn();
      setWeb3Ready({ fm, web3 });
      setWeb3IsInitialized(true);
    };

    initializeWeb3();
  }, []);

  return {
    accounts,
    signOut,
    signIn,
    isSignedIn,
    web3Ready,
    web3IsInitialized,
  };
};

export default useFortmatic;
/**
 * A jscodeshift codemod for replacing import & export paths with their full
 * paths, including extensions. Effectively fixes imports for use as ES modules
 * in Node.js.
 *
 * Copyright Eemeli Aro <eemeli@gmail.com>
 *
 * Permission to use, copy, modify, and/or distribute this software for any
 * purpose with or without fee is hereby granted.
 */

const { dirname, relative, resolve, sep } = require('path')

const useFullFilePath = dir => path => {
  const { source } = path.value
  if (source && source.value.startsWith('.')) {
    const absPath = require.resolve(resolve(dir, source.value))
    const relPath = relative(dir, absPath)
    source.value = relPath.startsWith('.') ? relPath : `.${sep}${relPath}`
  }
}

module.exports = function useFullImportFilePaths(fileInfo, api) {
  const j = api.jscodeshift
  const root = j(fileInfo.source)
  const dir = dirname(resolve(fileInfo.path))
  const fix = useFullFilePath(dir)
  for (const d of [
    j.ImportDeclaration,
    j.ExportAllDeclaration,
    j.ExportNamedDeclaration
  ])
    root.find(d).forEach(fix)
  return root.toSource({ quote: 'single' })
}

let labelForId = 0;
export default const useInputId = () => {
  const labelId = React.useRef(() => labelForId++);
  return `my-input-${labelId.current}`;
};

import { useState } from 'react';

const configureLocalStorage = key => initialValue => {
  const [state, setState] = useState(() => {
    try {
      const value = localStorage.getItem(key);
      return value ? JSON.parse(value) : initialValue;
    } catch (e) {
      console.log(e);
      return initialValue;
    }
  }, initialValue);

  const storeValue = value => {
    const valueToStore = typeof value === 'function' ? value(state) : value;

    try {
      localStorage.setItem(key, JSON.stringify(valueToStore));
    } catch (err) {
      console.log(err);
      // This space intentionally left blank.
    }
    setState(valueToStore);
  };
  return [state, storeValue];
};

export { configureLocalStorage };

import { useRef } from 'react';

const usePromise = () => {
  const ref = [];
  const container = useRef(ref);

  ref[0] = new Promise((resolve, reject) => {
    ref[1] = resolve;
    ref[2] = reject;
  });

  // [promise, resolve, reject]
  return container.current;
};

export { usePromise };

function useWindowWidth() {
  const [width, setWidth] = useState(window.innerWidth);
  
  useEffect(() => {
    const handleResize = () => setWidth(window.innerWidth);
    window.addEventListener('resize', handleResize);
    return () => {
      window.removeEventListener('resize', handleResize);
    };
  });
  
  return width;
}

/*global YUI:true */
YUI.add("view-home", function(Y) {
    var L = Y.Lang,
        gw2 = Y.namespace("GW2"),
        Views = Y.namespace("GW2.Views"),
        Extensions = Y.namespace("GW2.Extensions");
    
    Views.Home = Y.Base.create("homeView", Y.View, [
        Extensions.ViewParent
    ], {
        template : Y.namespace("GW2.Templates").home,
        
        initializer : function(config) {
            this.set("views", {
                carousel : new Views.HomeCarousel({
                    models : config.carousel
                }),
                
                featured : new Views.HomeList({
                    type   : "featured",
                    models : config.featured
                }),
                
                hot : new Views.HomeList({
                    type   : "hot",
                    models : config.hot
                }),
                
                sidebar : new Views.HomeSidebar({
                    history : config.history
                })
            });
        },
        
        //NO-OP
        destructor : function() {},
        
        render : function() {
            this.get("container").setContent(this.template());
            
            return this;
        }
    }, {
        ATTRS : {
            items : null
        }
    });
    
}, "@VERSION@", {
    requires : [
        "base",
        "view",
        "view-home-carousel",
        "view-home-list",
        "view-home-sidebar",
        "extension-view-purchasing",
        "extension-view-classer",
        "extension-view-tooltips",
        "tabview",
        "scrollview",
        "scrollview-paginator",
        "gw2-template-home"
    ]
});

/*global YUI:true */
YUI.add("view-home-list", function(Y) {
    var Templates = Y.namespace("GW2.Templates");
    
    Y.namespace("GW2.Views").HomeList = Y.Base.create("homeListView", Y.View, [], {
        template : Templates["home-list"],
        
        events : {
            ".browse" : {
                click : "_clickBrowse"
            }
        },
        
        render : function() {
            var items = this.get("models");
            
            this.get("container").setHTML(this.template({
                type  : this.get("type"),
                title : this.get("title"),
                items : items.toJSON()
            }));
            
            return this;
        },
        
        _clickBrowse : function(e) {
            e.preventDefault();
            
            this.fire("search", {
                search : {
                    tag : e.currentTarget.getData("tag")
                }
            });
        }
    }, {
        ATTRS : {
            type  : null,
            title : null
        }
    });
    
}, "@VERSION@", {
    requires : [
        "base",
        "view",
        "gw2-template-home-list",
        "gw2-template-home-item",
        "gw2-template-item-buttons"
    ]
});
