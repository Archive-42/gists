<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>website-crawlers</title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
  </head>
  <body>
    <h1 id="awesome-crawler-awesome">
      Awesome-crawler
      <img
        src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg"
        alt="Awesome"
      />
    </h1>
    <p>
      A collection of awesome web crawler,spider and resources in different
      languages.
    </p>
    <h2 id="contents">Contents</h2>
    <ul>
      <li><a href="#python">Python</a></li>
      <li><a href="#java">Java</a></li>
      <li><a href="#c">C#</a></li>
      <li><a href="#javascript">JavaScript</a></li>
      <li><a href="#php">PHP</a></li>
      <li><a href="#c-1">C++</a></li>
      <li><a href="#c-2">C</a></li>
      <li><a href="#ruby">Ruby</a></li>
      <li><a href="#r">R</a></li>
      <li><a href="#erlang">Erlang</a></li>
      <li><a href="#perl">Perl</a></li>
      <li><a href="#go">Go</a></li>
      <li><a href="#scala">Scala</a></li>
    </ul>
    <h2 id="python">Python</h2>
    <ul>
      <li>
        <a href="https://github.com/scrapy/scrapy">Scrapy</a> - A fast
        high-level screen scraping and web crawling framework.
        <ul>
          <li>
            <a href="https://github.com/holgerd77/django-dynamic-scraper"
              >django-dynamic-scraper</a
            >
            - Creating Scrapy scrapers via the Django admin interface.
          </li>
          <li>
            <a href="https://github.com/rolando/scrapy-redis">Scrapy-Redis</a> -
            Redis-based components for Scrapy.
          </li>
          <li>
            <a href="https://github.com/istresearch/scrapy-cluster"
              >scrapy-cluster</a
            >
            - Uses Redis and Kafka to create a distributed on demand scraping
            cluster.
          </li>
          <li>
            <a href="https://github.com/gnemoug/distribute_crawler"
              >distribute_crawler</a
            >
            - Uses scrapy,redis, mongodb,graphite to create a distributed
            spider.
          </li>
        </ul>
      </li>
      <li>
        <a href="https://github.com/binux/pyspider">pyspider</a> - A powerful
        spider system.
      </li>
      <li>
        <a href="https://github.com/cocrawler/cocrawler">CoCrawler</a> - A
        versatile web crawler built using modern tools and concurrency.
      </li>
      <li>
        <a href="https://github.com/chineking/cola">cola</a> - A distributed
        crawling framework.
      </li>
      <li>
        <a href="https://github.com/matiasb/demiurge">Demiurge</a> -
        PyQuery-based scraping micro-framework.
      </li>
      <li>
        <a href="https://github.com/scrapy/scrapely">Scrapely</a> - A
        pure-python HTML screen-scraping library.
      </li>
      <li>
        <a href="http://pythonhosted.org/feedparser/">feedparser</a> - Universal
        feed parser.
      </li>
      <li>
        <a href="https://github.com/soimort/you-get">you-get</a> - Dumb
        downloader that scrapes the web.
      </li>
      <li><a href="http://grablib.org/">Grab</a> - Site scraping framework.</li>
      <li>
        <a href="https://github.com/hickford/MechanicalSoup">MechanicalSoup</a>
        - A Python library for automating interaction with websites.
      </li>
      <li>
        <a href="https://github.com/scrapinghub/portia">portia</a> - Visual
        scraping for Scrapy.
      </li>
      <li>
        <a href="https://github.com/jmg/crawley">crawley</a> - Pythonic Crawling
        / Scraping Framework based on Non Blocking I/O operations.
      </li>
      <li>
        <a href="https://github.com/jmcarp/robobrowser">RoboBrowser</a> - A
        simple, Pythonic library for browsing the web without a standalone web
        browser.
      </li>
      <li>
        <a href="https://github.com/manning23/MSpider">MSpider</a> - A simple
        ,easy spider using gevent and js render.
      </li>
      <li>
        <a href="https://github.com/douban/brownant">brownant</a> - A
        lightweight web data extracting framework.
      </li>
      <li>
        <a href="https://github.com/xianhu/PSpider">PSpider</a> - A simple
        spider frame in Python3.
      </li>
      <li>
        <a href="https://github.com/gaojiuli/gain">Gain</a> - Web crawling
        framework based on asyncio for everyone.
      </li>
      <li>
        <a href="https://github.com/iogf/sukhoi">sukhoi</a> - Minimalist and
        powerful Web Crawler.
      </li>
      <li>
        <a href="https://github.com/rivermont/spidy">spidy</a> - The simple,
        easy to use command line web crawler.
      </li>
      <li>
        <a href="https://github.com/codelucas/newspaper">newspaper</a> - News,
        full-text, and article metadata extraction in Python 3
      </li>
      <li>
        <a href="https://github.com/howie6879/aspider">aspider</a> - An async
        web scraping micro-framework based on asyncio.
      </li>
    </ul>
    <h2 id="java">Java</h2>
    <ul>
      <li>
        <a href="https://github.com/ViDA-NYU/ache">ACHE Crawler</a> - An easy to
        use web crawler for domain-specific search.
      </li>
      <li>
        <a href="http://nutch.apache.org/">Apache Nutch</a> - Highly extensible,
        highly scalable web crawler for production environment.
        <ul>
          <li>
            <a href="https://github.com/yahoo/anthelion">anthelion</a> - A
            plugin for Apache Nutch to crawl semantic annotations within HTML
            pages.
          </li>
        </ul>
      </li>
      <li>
        <a href="https://github.com/yasserg/crawler4j">Crawler4j</a> - Simple
        and lightweight web crawler.
      </li>
      <li>
        <a href="http://jsoup.org/">JSoup</a> - Scrapes, parses, manipulates and
        cleans HTML.
      </li>
      <li>
        <a href="http://www.cs.cmu.edu/~rcm/websphinx/">websphinx</a> -
        Website-Specific Processors for HTML information extraction.
      </li>
      <li>
        <a href="http://www.opensearchserver.com/">Open Search Server</a> - A
        full set of search functions. Build your own indexing strategy. Parsers
        extract full-text data. The crawlers can index everything.
      </li>
      <li>
        <a href="https://github.com/xtuhcy/gecco">Gecco</a> - A easy to use
        lightweight web crawler
      </li>
      <li>
        <a href="https://github.com/CrawlScript/WebCollector">WebCollector</a> -
        Simple interfaces for crawling the Web,you can setup a multi-threaded
        web crawler in less than 5 minutes.
      </li>
      <li>
        <a href="https://github.com/code4craft/webmagic">Webmagic</a> - A
        scalable crawler framework.
      </li>
      <li>
        <a href="https://git.oschina.net/l-weiwei/spiderman">Spiderman</a> - A
        scalable ,extensible, multi-threaded web crawler.
        <ul>
          <li>
            <a href="http://git.oschina.net/l-weiwei/Spiderman2">Spiderman2</a>
            - A distributed web crawler framework,support js render.
          </li>
        </ul>
      </li>
      <li>
        <a href="https://github.com/internetarchive/heritrix3">Heritrix3</a> -
        Extensible, web-scale, archival-quality web crawler project.
      </li>
      <li>
        <a href="https://github.com/zhegexiaohuozi/SeimiCrawler"
          >SeimiCrawler</a
        >
        - An agile, distributed crawler framework.
      </li>
      <li>
        <a href="http://github.com/DigitalPebble/storm-crawler/"
          >StormCrawler</a
        >
        - An open source collection of resources for building low-latency,
        scalable web crawlers on Apache Storm
      </li>
      <li>
        <a href="https://github.com/USCDataScience/sparkler">Spark-Crawler</a> -
        Evolving Apache Nutch to run on Spark.
      </li>
      <li>
        <a href="https://github.com/pkwenda/webBee">webBee</a> - A DFS web
        spider.
      </li>
      <li>
        <a href="https://github.com/ssssssss-team/spider-flow">spider-flow</a> -
        A visual spider framework, it’s so good that you don’t need to write any
        code to crawl the website.
      </li>
    </ul>
    <h2 id="c">C</h2>
    <ul>
      <li>
        <a href="http://www.findbestopensource.com/product/ccrawler"
          >ccrawler</a
        >
        - Built in C# 3.5 version. it contains a simple extension of web content
        categorizer, which can saparate between the web page depending on their
        content.
      </li>
      <li>
        <a href="https://github.com/lei-zhu/SimpleCrawler">SimpleCrawler</a> -
        Simple spider base on mutithreading, regluar expression.
      </li>
      <li>
        <a href="https://github.com/zlzforever/DotnetSpider">DotnetSpider</a> -
        This is a cross platfrom, ligth spider develop by C#.
      </li>
      <li>
        <a href="https://github.com/sjdirect/abot">Abot</a> - C# web crawler
        built for speed and flexibility.
      </li>
      <li>
        <a href="https://github.com/ferventdesert/Hawk">Hawk</a> - Advanced
        Crawler and ETL tool written in C#/WPF.
      </li>
      <li>
        <a href="https://github.com/JonCanning/SkyScraper">SkyScraper</a> - An
        asynchronous web scraper / web crawler using async / await and Reactive
        Extensions.
      </li>
      <li>
        <a href="https://github.com/TurnerSoftware/InfinityCrawler"
          >Infinity Crawler</a
        >
        - A simple but powerful web crawler library in C#.
      </li>
    </ul>
    <h2 id="javascript">JavaScript</h2>
    <ul>
      <li>
        <a href="https://github.com/ruipgil/scraperjs">scraperjs</a> - A
        complete and versatile web scraper.
      </li>
      <li>
        <a href="https://github.com/IonicaBizau/scrape-it">scrape-it</a> - A
        Node.js scraper for humans.
      </li>
      <li>
        <a href="https://github.com/cgiffard/node-simplecrawler"
          >simplecrawler</a
        >
        - Event driven web crawler.
      </li>
      <li>
        <a href="https://github.com/bda-research/node-crawler">node-crawler</a>
        - Node-crawler has clean,simple api.
      </li>
      <li>
        <a href="https://github.com/antivanov/js-crawler">js-crawler</a> - Web
        crawler for Node.JS, both HTTP and HTTPS are supported.
      </li>
      <li>
        <a href="https://github.com/zhuyingda/webster">webster</a> - A reliable
        web crawling framework which can scrape ajax and js rendered content in
        a web page.
      </li>
      <li>
        <a href="https://github.com/lapwinglabs/x-ray">x-ray</a> - Web scraper
        with pagination and crawler support.
      </li>
      <li>
        <a href="https://github.com/rchipka/node-osmosis">node-osmosis</a> -
        HTML/XML parser and web scraper for Node.js.
      </li>
      <li>
        <a href="https://github.com/martinsbalodis/web-scraper-chrome-extension"
          >web-scraper-chrome-extension</a
        >
        - Web data extraction tool implemented as chrome extension.
      </li>
      <li>
        <a href="https://github.com/brendonboshell/supercrawler"
          >supercrawler</a
        >
        - Define custom handlers to parse content. Obeys robots.txt, rate limits
        and concurrency limits.
      </li>
      <li>
        <a href="https://github.com/yujiosaka/headless-chrome-crawler"
          >headless-chrome-crawler</a
        >
        - Headless Chrome crawls with jQuery support
      </li>
      <li>
        <a href="https://github.com/n0tan3rd/squidwarc">Squidwarc</a> - High
        fidelity, user scriptable, archival crawler that uses Chrome or Chromium
        with or without a head
      </li>
    </ul>
    <h2 id="php">PHP</h2>
    <ul>
      <li>
        <a href="https://github.com/FriendsOfPHP/Goutte">Goutte</a> - A screen
        scraping and web crawling library for PHP.
        <ul>
          <li>
            <a href="https://github.com/dweidner/laravel-goutte"
              >laravel-goutte</a
            >
            - Laravel 5 Facade for Goutte.
          </li>
        </ul>
      </li>
      <li>
        <a href="https://github.com/symfony/dom-crawler">dom-crawler</a> - The
        DomCrawler component eases DOM navigation for HTML and XML documents.
      </li>
      <li>
        <a href="https://github.com/jae-jae/QueryList">QueryList</a> - The
        progressive PHP crawler framework.
      </li>
      <li>
        <a href="https://github.com/hightman/pspider">pspider</a> - Parallel web
        crawler written in PHP.
      </li>
      <li>
        <a href="https://github.com/mvdbos/php-spider">php-spider</a> - A
        configurable and extensible PHP web spider.
      </li>
      <li>
        <a href="https://github.com/spatie/crawler">spatie/crawler</a> - An easy
        to use, powerful crawler implemented in PHP. Can execute Javascript.
      </li>
      <li>
        <a href="https://github.com/crawlzone/crawlzone">crawlzone/crawlzone</a>
        - Crawlzone is a fast asynchronous internet crawling framework for PHP.
      </li>
    </ul>
    <h2 id="c-1">C++</h2>
    <ul>
      <li>
        <a href="https://github.com/gigablast/open-source-search-engine"
          >open-source-search-engine</a
        >
        - A distributed open source search engine and spider/crawler written in
        C/C++.
      </li>
    </ul>
    <h2 id="c-2">C</h2>
    <ul>
      <li>
        <a href="https://github.com/xroche/httrack">httrack</a> - Copy websites
        to your computer.
      </li>
    </ul>
    <h2 id="ruby">Ruby</h2>
    <ul>
      <li>
        <a href="https://github.com/sparklemotion/nokogiri">Nokogiri</a> - A
        Rubygem providing HTML, XML, SAX, and Reader parsers with XPath and CSS
        selector support.
      </li>
      <li>
        <a href="https://github.com/propublica/upton">upton</a> - A
        batteries-included framework for easy web-scraping. Just add CSS(Or do
        more).
      </li>
      <li>
        <a href="https://github.com/felipecsl/wombat">wombat</a> - Lightweight
        Ruby web crawler/scraper with an elegant DSL which extracts structured
        data from pages.
      </li>
      <li>
        <a href="https://github.com/joenorton/rubyretriever">RubyRetriever</a> -
        RubyRetriever is a Web Crawler, Scraper &amp; File Harvester.
      </li>
      <li>
        <a href="https://github.com/postmodern/spidr">Spidr</a> - Spider a site
        ,multiple domains, certain links or infinitely.
      </li>
      <li>
        <a href="https://github.com/stewartmckee/cobweb">Cobweb</a> - Web
        crawler with very flexible crawling options, standalone or using
        sidekiq.
      </li>
      <li>
        <a href="https://github.com/sparklemotion/mechanize">mechanize</a> -
        Automated web interaction &amp; crawling.
      </li>
    </ul>
    <h2 id="r">R</h2>
    <ul>
      <li>
        <a href="https://github.com/hadley/rvest">rvest</a> - Simple web
        scraping for R.
      </li>
    </ul>
    <h2 id="erlang">Erlang</h2>
    <ul>
      <li>
        <a href="https://github.com/matteoredaelli/ebot">ebot</a> - A scalable,
        distribuited and highly configurable web cawler.
      </li>
    </ul>
    <h2 id="perl">Perl</h2>
    <ul>
      <li>
        <a href="https://github.com/miyagawa/web-scraper">web-scraper</a> - Web
        Scraping Toolkit using HTML and CSS Selectors or XPath expressions.
      </li>
    </ul>
    <h2 id="go">Go</h2>
    <ul>
      <li>
        <a href="https://github.com/henrylee2cn/pholcus">pholcus</a> - A
        distributed, high concurrency and powerful web crawler.
      </li>
      <li>
        <a href="https://github.com/PuerkitoBio/gocrawl">gocrawl</a> - Polite,
        slim and concurrent web crawler.
      </li>
      <li>
        <a href="https://github.com/PuerkitoBio/fetchbot">fetchbot</a> - A
        simple and flexible web crawler that follows the robots.txt policies and
        crawl delays.
      </li>
      <li>
        <a href="https://github.com/hu17889/go_spider">go_spider</a> - An
        awesome Go concurrent Crawler(spider) framework.
      </li>
      <li>
        <a href="https://github.com/shiyanhui/dht">dht</a> - BitTorrent DHT
        Protocol &amp;&amp; DHT Spider.
      </li>
      <li>
        <a href="https://github.com/wcong/ants-go">ants-go</a> - A open source,
        distributed, restful crawler engine in golang.
      </li>
      <li>
        <a href="https://github.com/yhat/scrape">scrape</a> - A simple, higher
        level interface for Go web scraping.
      </li>
      <li>
        <a href="https://github.com/wspl/creeper">creeper</a> - The Next
        Generation Crawler Framework (Go).
      </li>
      <li>
        <a href="https://github.com/asciimoo/colly">colly</a> - Fast and Elegant
        Scraping Framework for Gophers.
      </li>
      <li>
        <a href="https://github.com/MontFerret/ferret">ferret</a> - Declarative
        web scraping.
      </li>
      <li>
        <a href="https://github.com/slotix/dataflowkit">Dataflow kit</a> -
        Extract structured data from web pages. Web sites scraping.
      </li>
    </ul>
    <h2 id="scala">Scala</h2>
    <ul>
      <li>
        <a href="https://github.com/bplawler/crawler">crawler</a> - Scala DSL
        for web crawling.
      </li>
      <li>
        <a href="https://github.com/gaocegege/scrala">scrala</a> - Scala
        crawler(spider) framework, inspired by scrapy.
      </li>
      <li>
        <a href="https://github.com/reggoodwin/ferrit">ferrit</a> - Ferrit is a
        web crawler service written in Scala using Akka, Spray and Cassandra.
      </li>
    </ul>
  </body>
</html>
